digraph {
	graph [size="70.05,70.05"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1948135508224 [label="
 (1, 6, 128, 128)" fillcolor=darkolivegreen1]
	1948135148944 [label=ConvolutionBackward0]
	1948135149136 -> 1948135148944
	1948135149136 [label=ReluBackward0]
	1948135146064 -> 1948135149136
	1948135146064 [label=NativeBatchNormBackward0]
	1948909911392 -> 1948135146064
	1948909911392 [label=ConvolutionBackward0]
	1948909910048 -> 1948909911392
	1948909910048 [label=ReluBackward0]
	1948909909664 -> 1948909910048
	1948909909664 [label=NativeBatchNormBackward0]
	1948909911296 -> 1948909909664
	1948909911296 [label=ConvolutionBackward0]
	1948909910576 -> 1948909911296
	1948909910576 [label=CatBackward0]
	1948909910384 -> 1948909910576
	1948909910384 [label=ReluBackward0]
	1948909911440 -> 1948909910384
	1948909911440 [label=NativeBatchNormBackward0]
	1948909911344 -> 1948909911440
	1948909911344 [label=ConvolutionBackward0]
	1948909910480 -> 1948909911344
	1948909910480 [label=ReluBackward0]
	1948909908416 -> 1948909910480
	1948909908416 [label=NativeBatchNormBackward0]
	1948909909376 -> 1948909908416
	1948909909376 [label=ConvolutionBackward0]
	1948909909232 -> 1948909909376
	1948135366800 [label="double_conv.block.0.weight
 (64, 3, 3, 3)" fillcolor=lightblue]
	1948135366800 -> 1948909909232
	1948909909232 [label=AccumulateGrad]
	1948909910144 -> 1948909909376
	1948173686880 [label="double_conv.block.0.bias
 (64)" fillcolor=lightblue]
	1948173686880 -> 1948909910144
	1948909910144 [label=AccumulateGrad]
	1948909911248 -> 1948909908416
	1948216955024 [label="double_conv.block.1.weight
 (64)" fillcolor=lightblue]
	1948216955024 -> 1948909911248
	1948909911248 [label=AccumulateGrad]
	1948909910912 -> 1948909908416
	1948135368800 [label="double_conv.block.1.bias
 (64)" fillcolor=lightblue]
	1948135368800 -> 1948909910912
	1948909910912 [label=AccumulateGrad]
	1948909910192 -> 1948909911344
	1948135370400 [label="double_conv.block.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1948135370400 -> 1948909910192
	1948909910192 [label=AccumulateGrad]
	1948909909952 -> 1948909911344
	1948135370160 [label="double_conv.block.3.bias
 (64)" fillcolor=lightblue]
	1948135370160 -> 1948909909952
	1948909909952 [label=AccumulateGrad]
	1948909910096 -> 1948909911440
	1948135366720 [label="double_conv.block.4.weight
 (64)" fillcolor=lightblue]
	1948135366720 -> 1948909910096
	1948909910096 [label=AccumulateGrad]
	1948909910528 -> 1948909911440
	1948135367280 [label="double_conv.block.4.bias
 (64)" fillcolor=lightblue]
	1948135367280 -> 1948909910528
	1948909910528 [label=AccumulateGrad]
	1948909910336 -> 1948909910576
	1948909910336 [label=ConvolutionBackward0]
	1948909908128 -> 1948909910336
	1948909908128 [label=ReluBackward0]
	1948909910672 -> 1948909908128
	1948909910672 [label=NativeBatchNormBackward0]
	1948909908368 -> 1948909910672
	1948909908368 [label=ConvolutionBackward0]
	1948909911920 -> 1948909908368
	1948909911920 [label=ReluBackward0]
	1948909910432 -> 1948909911920
	1948909910432 [label=NativeBatchNormBackward0]
	1948909911872 -> 1948909910432
	1948909911872 [label=ConvolutionBackward0]
	1948909909136 -> 1948909911872
	1948909909136 [label=CatBackward0]
	1948909908224 -> 1948909909136
	1948909908224 [label=ReluBackward0]
	1948909910720 -> 1948909908224
	1948909910720 [label=NativeBatchNormBackward0]
	1948909908464 -> 1948909910720
	1948909908464 [label=ConvolutionBackward0]
	1948173818464 -> 1948909908464
	1948173818464 [label=ReluBackward0]
	1948173819232 -> 1948173818464
	1948173819232 [label=NativeBatchNormBackward0]
	1948173818848 -> 1948173819232
	1948173818848 [label=ConvolutionBackward0]
	1948135104128 -> 1948173818848
	1948135104128 [label=MaxPool2DWithIndicesBackward0]
	1948909910384 -> 1948135104128
	1948135104080 -> 1948173818848
	1948135368400 [label="down_block_1.block.1.block.0.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	1948135368400 -> 1948135104080
	1948135104080 [label=AccumulateGrad]
	1948135104032 -> 1948173818848
	1948135368240 [label="down_block_1.block.1.block.0.bias
 (128)" fillcolor=lightblue]
	1948135368240 -> 1948135104032
	1948135104032 [label=AccumulateGrad]
	1948173819184 -> 1948173819232
	1948135391456 [label="down_block_1.block.1.block.1.weight
 (128)" fillcolor=lightblue]
	1948135391456 -> 1948173819184
	1948173819184 [label=AccumulateGrad]
	1948173816976 -> 1948173819232
	1948135392016 [label="down_block_1.block.1.block.1.bias
 (128)" fillcolor=lightblue]
	1948135392016 -> 1948173816976
	1948173816976 [label=AccumulateGrad]
	1948173817264 -> 1948909908464
	1948135392736 [label="down_block_1.block.1.block.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1948135392736 -> 1948173817264
	1948173817264 [label=AccumulateGrad]
	1948173818320 -> 1948909908464
	1948135393376 [label="down_block_1.block.1.block.3.bias
 (128)" fillcolor=lightblue]
	1948135393376 -> 1948173818320
	1948173818320 [label=AccumulateGrad]
	1948909910240 -> 1948909910720
	1948135394416 [label="down_block_1.block.1.block.4.weight
 (128)" fillcolor=lightblue]
	1948135394416 -> 1948909910240
	1948909910240 [label=AccumulateGrad]
	1948909911632 -> 1948909910720
	1948135394576 [label="down_block_1.block.1.block.4.bias
 (128)" fillcolor=lightblue]
	1948135394576 -> 1948909911632
	1948909911632 [label=AccumulateGrad]
	1948909909808 -> 1948909909136
	1948909909808 [label=ConvolutionBackward0]
	1948909911968 -> 1948909909808
	1948909911968 [label=ReluBackward0]
	1948173817312 -> 1948909911968
	1948173817312 [label=NativeBatchNormBackward0]
	1948135103168 -> 1948173817312
	1948135103168 [label=ConvolutionBackward0]
	1948135104416 -> 1948135103168
	1948135104416 [label=ReluBackward0]
	1948135104272 -> 1948135104416
	1948135104272 [label=NativeBatchNormBackward0]
	1948135103120 -> 1948135104272
	1948135103120 [label=ConvolutionBackward0]
	1948135102736 -> 1948135103120
	1948135102736 [label=CatBackward0]
	1948135102544 -> 1948135102736
	1948135102544 [label=ReluBackward0]
	1948135102400 -> 1948135102544
	1948135102400 [label=NativeBatchNormBackward0]
	1948135102256 -> 1948135102400
	1948135102256 [label=ConvolutionBackward0]
	1948135102016 -> 1948135102256
	1948135102016 [label=ReluBackward0]
	1948135101824 -> 1948135102016
	1948135101824 [label=NativeBatchNormBackward0]
	1948135101728 -> 1948135101824
	1948135101728 [label=ConvolutionBackward0]
	1948135101440 -> 1948135101728
	1948135101440 [label=MaxPool2DWithIndicesBackward0]
	1948909908224 -> 1948135101440
	1948135101536 -> 1948135101728
	1948135394096 [label="down_block_2.block.1.block.0.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	1948135394096 -> 1948135101536
	1948135101536 [label=AccumulateGrad]
	1948135101584 -> 1948135101728
	1948135395136 [label="down_block_2.block.1.block.0.bias
 (256)" fillcolor=lightblue]
	1948135395136 -> 1948135101584
	1948135101584 [label=AccumulateGrad]
	1948135101776 -> 1948135101824
	1948135394496 [label="down_block_2.block.1.block.1.weight
 (256)" fillcolor=lightblue]
	1948135394496 -> 1948135101776
	1948135101776 [label=AccumulateGrad]
	1948135101920 -> 1948135101824
	1948135394816 [label="down_block_2.block.1.block.1.bias
 (256)" fillcolor=lightblue]
	1948135394816 -> 1948135101920
	1948135101920 [label=AccumulateGrad]
	1948135102064 -> 1948135102256
	1948135394016 [label="down_block_2.block.1.block.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1948135394016 -> 1948135102064
	1948135102064 [label=AccumulateGrad]
	1948135102112 -> 1948135102256
	1948135394336 [label="down_block_2.block.1.block.3.bias
 (256)" fillcolor=lightblue]
	1948135394336 -> 1948135102112
	1948135102112 [label=AccumulateGrad]
	1948135102304 -> 1948135102400
	1948135395056 [label="down_block_2.block.1.block.4.weight
 (256)" fillcolor=lightblue]
	1948135395056 -> 1948135102304
	1948135102304 [label=AccumulateGrad]
	1948135102496 -> 1948135102400
	1948135392336 [label="down_block_2.block.1.block.4.bias
 (256)" fillcolor=lightblue]
	1948135392336 -> 1948135102496
	1948135102496 [label=AccumulateGrad]
	1948135102592 -> 1948135102736
	1948135102592 [label=ConvolutionBackward0]
	1948135101968 -> 1948135102592
	1948135101968 [label=ReluBackward0]
	1948135101008 -> 1948135101968
	1948135101008 [label=NativeBatchNormBackward0]
	1948135101296 -> 1948135101008
	1948135101296 [label=ConvolutionBackward0]
	1948135100816 -> 1948135101296
	1948135100816 [label=ReluBackward0]
	1948135100576 -> 1948135100816
	1948135100576 [label=NativeBatchNormBackward0]
	1948135101488 -> 1948135100576
	1948135101488 [label=ConvolutionBackward0]
	1948135103072 -> 1948135101488
	1948135103072 [label=CatBackward0]
	1948135103504 -> 1948135103072
	1948135103504 [label=ReluBackward0]
	1948135101056 -> 1948135103504
	1948135101056 [label=NativeBatchNormBackward0]
	1948135101200 -> 1948135101056
	1948135101200 [label=ConvolutionBackward0]
	1948910358832 -> 1948135101200
	1948910358832 [label=ReluBackward0]
	1948910361808 -> 1948910358832
	1948910361808 [label=NativeBatchNormBackward0]
	1948910359120 -> 1948910361808
	1948910359120 [label=ConvolutionBackward0]
	1948910360416 -> 1948910359120
	1948910360416 [label=MaxPool2DWithIndicesBackward0]
	1948135102544 -> 1948910360416
	1948910362048 -> 1948910359120
	1948135391696 [label="down_block_3.block.1.block.0.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	1948135391696 -> 1948910362048
	1948910362048 [label=AccumulateGrad]
	1948910362000 -> 1948910359120
	1948135391296 [label="down_block_3.block.1.block.0.bias
 (512)" fillcolor=lightblue]
	1948135391296 -> 1948910362000
	1948910362000 [label=AccumulateGrad]
	1948910361856 -> 1948910361808
	1948135392656 [label="down_block_3.block.1.block.1.weight
 (512)" fillcolor=lightblue]
	1948135392656 -> 1948910361856
	1948910361856 [label=AccumulateGrad]
	1948910361712 -> 1948910361808
	1948135393296 [label="down_block_3.block.1.block.1.bias
 (512)" fillcolor=lightblue]
	1948135393296 -> 1948910361712
	1948910361712 [label=AccumulateGrad]
	1948910359024 -> 1948135101200
	1948135393936 [label="down_block_3.block.1.block.3.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1948135393936 -> 1948910359024
	1948910359024 [label=AccumulateGrad]
	1948910359168 -> 1948135101200
	1948135393056 [label="down_block_3.block.1.block.3.bias
 (512)" fillcolor=lightblue]
	1948135393056 -> 1948910359168
	1948910359168 [label=AccumulateGrad]
	1948135100672 -> 1948135101056
	1948135393616 [label="down_block_3.block.1.block.4.weight
 (512)" fillcolor=lightblue]
	1948135393616 -> 1948135100672
	1948135100672 [label=AccumulateGrad]
	1948910361904 -> 1948135101056
	1948135393696 [label="down_block_3.block.1.block.4.bias
 (512)" fillcolor=lightblue]
	1948135393696 -> 1948910361904
	1948910361904 [label=AccumulateGrad]
	1948135103216 -> 1948135103072
	1948135103216 [label=ConvolutionBackward0]
	1948135100528 -> 1948135103216
	1948135100528 [label=ReluBackward0]
	1948910362480 -> 1948135100528
	1948910362480 [label=NativeBatchNormBackward0]
	1948910358688 -> 1948910362480
	1948910358688 [label=ConvolutionBackward0]
	1948910362144 -> 1948910358688
	1948910362144 [label=ReluBackward0]
	1948910360128 -> 1948910362144
	1948910360128 [label=NativeBatchNormBackward0]
	1948910362240 -> 1948910360128
	1948910362240 [label=ConvolutionBackward0]
	1948910360224 -> 1948910362240
	1948910360224 [label=MaxPool2DWithIndicesBackward0]
	1948135103504 -> 1948910360224
	1948910362096 -> 1948910362240
	1948135392896 [label="down_block_4.block.1.block.0.weight
 (1024, 512, 3, 3)" fillcolor=lightblue]
	1948135392896 -> 1948910362096
	1948910362096 [label=AccumulateGrad]
	1948910362288 -> 1948910362240
	1948135392976 [label="down_block_4.block.1.block.0.bias
 (1024)" fillcolor=lightblue]
	1948135392976 -> 1948910362288
	1948910362288 [label=AccumulateGrad]
	1948910362192 -> 1948910360128
	1948216153408 [label="down_block_4.block.1.block.1.weight
 (1024)" fillcolor=lightblue]
	1948216153408 -> 1948910362192
	1948910362192 [label=AccumulateGrad]
	1948910358640 -> 1948910360128
	1948216152128 [label="down_block_4.block.1.block.1.bias
 (1024)" fillcolor=lightblue]
	1948216152128 -> 1948910358640
	1948910358640 [label=AccumulateGrad]
	1948910362336 -> 1948910358688
	1948216152768 [label="down_block_4.block.1.block.3.weight
 (1024, 1024, 3, 3)" fillcolor=lightblue]
	1948216152768 -> 1948910362336
	1948910362336 [label=AccumulateGrad]
	1948910362432 -> 1948910358688
	1948216152688 [label="down_block_4.block.1.block.3.bias
 (1024)" fillcolor=lightblue]
	1948216152688 -> 1948910362432
	1948910362432 [label=AccumulateGrad]
	1948910362528 -> 1948910362480
	1948216153328 [label="down_block_4.block.1.block.4.weight
 (1024)" fillcolor=lightblue]
	1948216153328 -> 1948910362528
	1948910362528 [label=AccumulateGrad]
	1948910361952 -> 1948910362480
	1948216153248 [label="down_block_4.block.1.block.4.bias
 (1024)" fillcolor=lightblue]
	1948216153248 -> 1948910361952
	1948910361952 [label=AccumulateGrad]
	1948910361760 -> 1948135103216
	1948216152608 [label="up_block_1.up_conv.weight
 (1024, 512, 2, 2)" fillcolor=lightblue]
	1948216152608 -> 1948910361760
	1948910361760 [label=AccumulateGrad]
	1948910361376 -> 1948135103216
	1948216152208 [label="up_block_1.up_conv.bias
 (512)" fillcolor=lightblue]
	1948216152208 -> 1948910361376
	1948910361376 [label=AccumulateGrad]
	1948135102928 -> 1948135101488
	1948216153968 [label="up_block_1.double_conv.block.0.weight
 (512, 1024, 3, 3)" fillcolor=lightblue]
	1948216153968 -> 1948135102928
	1948135102928 [label=AccumulateGrad]
	1948135102160 -> 1948135101488
	1948216153728 [label="up_block_1.double_conv.block.0.bias
 (512)" fillcolor=lightblue]
	1948216153728 -> 1948135102160
	1948135102160 [label=AccumulateGrad]
	1948135100480 -> 1948135100576
	1948216153488 [label="up_block_1.double_conv.block.1.weight
 (512)" fillcolor=lightblue]
	1948216153488 -> 1948135100480
	1948135100480 [label=AccumulateGrad]
	1948135100720 -> 1948135100576
	1948216153568 [label="up_block_1.double_conv.block.1.bias
 (512)" fillcolor=lightblue]
	1948216153568 -> 1948135100720
	1948135100720 [label=AccumulateGrad]
	1948135100864 -> 1948135101296
	1948216155168 [label="up_block_1.double_conv.block.3.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1948216155168 -> 1948135100864
	1948135100864 [label=AccumulateGrad]
	1948135100912 -> 1948135101296
	1948216155248 [label="up_block_1.double_conv.block.3.bias
 (512)" fillcolor=lightblue]
	1948216155248 -> 1948135100912
	1948135100912 [label=AccumulateGrad]
	1948135101248 -> 1948135101008
	1948216154848 [label="up_block_1.double_conv.block.4.weight
 (512)" fillcolor=lightblue]
	1948216154848 -> 1948135101248
	1948135101248 [label=AccumulateGrad]
	1948135101632 -> 1948135101008
	1948216154928 [label="up_block_1.double_conv.block.4.bias
 (512)" fillcolor=lightblue]
	1948216154928 -> 1948135101632
	1948135101632 [label=AccumulateGrad]
	1948135102208 -> 1948135102592
	1948216155808 [label="up_block_2.up_conv.weight
 (512, 256, 2, 2)" fillcolor=lightblue]
	1948216155808 -> 1948135102208
	1948135102208 [label=AccumulateGrad]
	1948135102448 -> 1948135102592
	1948216155888 [label="up_block_2.up_conv.bias
 (256)" fillcolor=lightblue]
	1948216155888 -> 1948135102448
	1948135102448 [label=AccumulateGrad]
	1948135102784 -> 1948135103120
	1948216154768 [label="up_block_2.double_conv.block.0.weight
 (256, 512, 3, 3)" fillcolor=lightblue]
	1948216154768 -> 1948135102784
	1948135102784 [label=AccumulateGrad]
	1948135102880 -> 1948135103120
	1948216154368 [label="up_block_2.double_conv.block.0.bias
 (256)" fillcolor=lightblue]
	1948216154368 -> 1948135102880
	1948135102880 [label=AccumulateGrad]
	1948135104224 -> 1948135104272
	1948216155488 [label="up_block_2.double_conv.block.1.weight
 (256)" fillcolor=lightblue]
	1948216155488 -> 1948135104224
	1948135104224 [label=AccumulateGrad]
	1948135104368 -> 1948135104272
	1948216156048 [label="up_block_2.double_conv.block.1.bias
 (256)" fillcolor=lightblue]
	1948216156048 -> 1948135104368
	1948135104368 [label=AccumulateGrad]
	1948135101680 -> 1948135103168
	1948216154208 [label="up_block_2.double_conv.block.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1948216154208 -> 1948135101680
	1948135101680 [label=AccumulateGrad]
	1948135101152 -> 1948135103168
	1948216154128 [label="up_block_2.double_conv.block.3.bias
 (256)" fillcolor=lightblue]
	1948216154128 -> 1948135101152
	1948135101152 [label=AccumulateGrad]
	1948135103264 -> 1948173817312
	1948216155408 [label="up_block_2.double_conv.block.4.weight
 (256)" fillcolor=lightblue]
	1948216155408 -> 1948135103264
	1948135103264 [label=AccumulateGrad]
	1948135104176 -> 1948173817312
	1948216154448 [label="up_block_2.double_conv.block.4.bias
 (256)" fillcolor=lightblue]
	1948216154448 -> 1948135104176
	1948135104176 [label=AccumulateGrad]
	1948173817408 -> 1948909909808
	1948135310576 [label="up_block_3.up_conv.weight
 (256, 128, 2, 2)" fillcolor=lightblue]
	1948135310576 -> 1948173817408
	1948173817408 [label=AccumulateGrad]
	1948173818128 -> 1948909909808
	1948135311136 [label="up_block_3.up_conv.bias
 (128)" fillcolor=lightblue]
	1948135311136 -> 1948173818128
	1948173818128 [label=AccumulateGrad]
	1948909908560 -> 1948909911872
	1948135312256 [label="up_block_3.double_conv.block.0.weight
 (128, 256, 3, 3)" fillcolor=lightblue]
	1948135312256 -> 1948909908560
	1948909908560 [label=AccumulateGrad]
	1948909908080 -> 1948909911872
	1948135312816 [label="up_block_3.double_conv.block.0.bias
 (128)" fillcolor=lightblue]
	1948135312816 -> 1948909908080
	1948909908080 [label=AccumulateGrad]
	1948909908032 -> 1948909910432
	1948135312896 [label="up_block_3.double_conv.block.1.weight
 (128)" fillcolor=lightblue]
	1948135312896 -> 1948909908032
	1948909908032 [label=AccumulateGrad]
	1948909908512 -> 1948909910432
	1948135313296 [label="up_block_3.double_conv.block.1.bias
 (128)" fillcolor=lightblue]
	1948135313296 -> 1948909908512
	1948909908512 [label=AccumulateGrad]
	1948909908656 -> 1948909908368
	1948135312656 [label="up_block_3.double_conv.block.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1948135312656 -> 1948909908656
	1948909908656 [label=AccumulateGrad]
	1948909908176 -> 1948909908368
	1948135312576 [label="up_block_3.double_conv.block.3.bias
 (128)" fillcolor=lightblue]
	1948135312576 -> 1948909908176
	1948909908176 [label=AccumulateGrad]
	1948909910768 -> 1948909910672
	1948135312496 [label="up_block_3.double_conv.block.4.weight
 (128)" fillcolor=lightblue]
	1948135312496 -> 1948909910768
	1948909910768 [label=AccumulateGrad]
	1948909912016 -> 1948909910672
	1948135311856 [label="up_block_3.double_conv.block.4.bias
 (128)" fillcolor=lightblue]
	1948135311856 -> 1948909912016
	1948909912016 [label=AccumulateGrad]
	1948909911488 -> 1948909910336
	1948135311536 [label="up_block_4.up_conv.weight
 (128, 64, 2, 2)" fillcolor=lightblue]
	1948135311536 -> 1948909911488
	1948909911488 [label=AccumulateGrad]
	1948909911776 -> 1948909910336
	1948135311456 [label="up_block_4.up_conv.bias
 (64)" fillcolor=lightblue]
	1948135311456 -> 1948909911776
	1948909911776 [label=AccumulateGrad]
	1948909911536 -> 1948909911296
	1948135310736 [label="up_block_4.double_conv.block.0.weight
 (64, 128, 3, 3)" fillcolor=lightblue]
	1948135310736 -> 1948909911536
	1948909911536 [label=AccumulateGrad]
	1948909910000 -> 1948909911296
	1948135310976 [label="up_block_4.double_conv.block.0.bias
 (64)" fillcolor=lightblue]
	1948135310976 -> 1948909910000
	1948909910000 [label=AccumulateGrad]
	1948909911680 -> 1948909909664
	1948135310896 [label="up_block_4.double_conv.block.1.weight
 (64)" fillcolor=lightblue]
	1948135310896 -> 1948909911680
	1948909911680 [label=AccumulateGrad]
	1948909909904 -> 1948909909664
	1948135310816 [label="up_block_4.double_conv.block.1.bias
 (64)" fillcolor=lightblue]
	1948135310816 -> 1948909909904
	1948909909904 [label=AccumulateGrad]
	1948909909712 -> 1948909911392
	1948135309616 [label="up_block_4.double_conv.block.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1948135309616 -> 1948909909712
	1948909909712 [label=AccumulateGrad]
	1948909909856 -> 1948909911392
	1948135309856 [label="up_block_4.double_conv.block.3.bias
 (64)" fillcolor=lightblue]
	1948135309856 -> 1948909909856
	1948909909856 [label=AccumulateGrad]
	1948909908320 -> 1948135146064
	1948135309776 [label="up_block_4.double_conv.block.4.weight
 (64)" fillcolor=lightblue]
	1948135309776 -> 1948909908320
	1948909908320 [label=AccumulateGrad]
	1948909908992 -> 1948135146064
	1948135309696 [label="up_block_4.double_conv.block.4.bias
 (64)" fillcolor=lightblue]
	1948135309696 -> 1948909908992
	1948909908992 [label=AccumulateGrad]
	1948135145776 -> 1948135148944
	1948135309936 [label="conv.weight
 (6, 64, 1, 1)" fillcolor=lightblue]
	1948135309936 -> 1948135145776
	1948135145776 [label=AccumulateGrad]
	1948135145584 -> 1948135148944
	1948135310656 [label="conv.bias
 (6)" fillcolor=lightblue]
	1948135310656 -> 1948135145584
	1948135145584 [label=AccumulateGrad]
	1948135148944 -> 1948135508224
}
