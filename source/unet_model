digraph {
	graph [size="70.05,70.05"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1948135506784 [label="
 (1, 6, 128, 128)" fillcolor=darkolivegreen1]
	1948135146496 [label=ConvolutionBackward0]
	1948135146784 -> 1948135146496
	1948135146784 [label=ReluBackward0]
	1948135146112 -> 1948135146784
	1948135146112 [label=NativeBatchNormBackward0]
	1948135147168 -> 1948135146112
	1948135147168 [label=ConvolutionBackward0]
	1948135147120 -> 1948135147168
	1948135147120 [label=ReluBackward0]
	1948135146928 -> 1948135147120
	1948135146928 [label=NativeBatchNormBackward0]
	1948135147408 -> 1948135146928
	1948135147408 [label=ConvolutionBackward0]
	1948135147840 -> 1948135147408
	1948135147840 [label=CatBackward0]
	1948135147792 -> 1948135147840
	1948135147792 [label=ReluBackward0]
	1948135148176 -> 1948135147792
	1948135148176 [label=NativeBatchNormBackward0]
	1948135147984 -> 1948135148176
	1948135147984 [label=ConvolutionBackward0]
	1948135148224 -> 1948135147984
	1948135148224 [label=ReluBackward0]
	1948135148416 -> 1948135148224
	1948135148416 [label=NativeBatchNormBackward0]
	1948135148704 -> 1948135148416
	1948135148704 [label=ConvolutionBackward0]
	1948135148656 -> 1948135148704
	1948173874416 [label="double_conv.block.0.weight
 (64, 3, 3, 3)" fillcolor=lightblue]
	1948173874416 -> 1948135148656
	1948135148656 [label=AccumulateGrad]
	1948135148272 -> 1948135148704
	1948173686480 [label="double_conv.block.0.bias
 (64)" fillcolor=lightblue]
	1948173686480 -> 1948135148272
	1948135148272 [label=AccumulateGrad]
	1948135148464 -> 1948135148416
	1948173874176 [label="double_conv.block.1.weight
 (64)" fillcolor=lightblue]
	1948173874176 -> 1948135148464
	1948135148464 [label=AccumulateGrad]
	1948135147936 -> 1948135148416
	1948173684960 [label="double_conv.block.1.bias
 (64)" fillcolor=lightblue]
	1948173684960 -> 1948135147936
	1948135147936 [label=AccumulateGrad]
	1948135148368 -> 1948135147984
	1948912976976 [label="double_conv.block.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1948912976976 -> 1948135148368
	1948135148368 [label=AccumulateGrad]
	1948135148128 -> 1948135147984
	1948912977136 [label="double_conv.block.3.bias
 (64)" fillcolor=lightblue]
	1948912977136 -> 1948135148128
	1948135148128 [label=AccumulateGrad]
	1948135147600 -> 1948135148176
	1948912979376 [label="double_conv.block.4.weight
 (64)" fillcolor=lightblue]
	1948912979376 -> 1948135147600
	1948135147600 [label=AccumulateGrad]
	1948135148032 -> 1948135148176
	1948912979136 [label="double_conv.block.4.bias
 (64)" fillcolor=lightblue]
	1948912979136 -> 1948135148032
	1948135148032 [label=AccumulateGrad]
	1948135147744 -> 1948135147840
	1948135147744 [label=ConvolutionBackward0]
	1948135148512 -> 1948135147744
	1948135148512 [label=ReluBackward0]
	1948135148752 -> 1948135148512
	1948135148752 [label=NativeBatchNormBackward0]
	1948135149040 -> 1948135148752
	1948135149040 [label=ConvolutionBackward0]
	1948135146016 -> 1948135149040
	1948135146016 [label=ReluBackward0]
	1948135818096 -> 1948135146016
	1948135818096 [label=NativeBatchNormBackward0]
	1948135818672 -> 1948135818096
	1948135818672 [label=ConvolutionBackward0]
	1948135821024 -> 1948135818672
	1948135821024 [label=CatBackward0]
	1948135820160 -> 1948135821024
	1948135820160 [label=ReluBackward0]
	1948135820016 -> 1948135820160
	1948135820016 [label=NativeBatchNormBackward0]
	1948135817760 -> 1948135820016
	1948135817760 [label=ConvolutionBackward0]
	1948135820592 -> 1948135817760
	1948135820592 [label=ReluBackward0]
	1948135820352 -> 1948135820592
	1948135820352 [label=NativeBatchNormBackward0]
	1948135817664 -> 1948135820352
	1948135817664 [label=ConvolutionBackward0]
	1948135817520 -> 1948135817664
	1948135817520 [label=MaxPool2DWithIndicesBackward0]
	1948135147792 -> 1948135817520
	1948135817808 -> 1948135817664
	1948912978736 [label="down_block_1.block.1.block.0.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	1948912978736 -> 1948135817808
	1948135817808 [label=AccumulateGrad]
	1948135819152 -> 1948135817664
	1948912979216 [label="down_block_1.block.1.block.0.bias
 (128)" fillcolor=lightblue]
	1948912979216 -> 1948135819152
	1948135819152 [label=AccumulateGrad]
	1948135818240 -> 1948135820352
	1948912979456 [label="down_block_1.block.1.block.1.weight
 (128)" fillcolor=lightblue]
	1948912979456 -> 1948135818240
	1948135818240 [label=AccumulateGrad]
	1948135820880 -> 1948135820352
	1948912979696 [label="down_block_1.block.1.block.1.bias
 (128)" fillcolor=lightblue]
	1948912979696 -> 1948135820880
	1948135820880 [label=AccumulateGrad]
	1948135820400 -> 1948135817760
	1948912979536 [label="down_block_1.block.1.block.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1948912979536 -> 1948135820400
	1948135820400 [label=AccumulateGrad]
	1948135821120 -> 1948135817760
	1948912978176 [label="down_block_1.block.1.block.3.bias
 (128)" fillcolor=lightblue]
	1948912978176 -> 1948135821120
	1948135821120 [label=AccumulateGrad]
	1948135817280 -> 1948135820016
	1948912978096 [label="down_block_1.block.1.block.4.weight
 (128)" fillcolor=lightblue]
	1948912978096 -> 1948135817280
	1948135817280 [label=AccumulateGrad]
	1948135819968 -> 1948135820016
	1948912976416 [label="down_block_1.block.1.block.4.bias
 (128)" fillcolor=lightblue]
	1948912976416 -> 1948135819968
	1948135819968 [label=AccumulateGrad]
	1948135820544 -> 1948135821024
	1948135820544 [label=ConvolutionBackward0]
	1948135820640 -> 1948135820544
	1948135820640 [label=ReluBackward0]
	1948135820208 -> 1948135820640
	1948135820208 [label=NativeBatchNormBackward0]
	1948135819056 -> 1948135820208
	1948135819056 [label=ConvolutionBackward0]
	1948135818624 -> 1948135819056
	1948135818624 [label=ReluBackward0]
	1948135818576 -> 1948135818624
	1948135818576 [label=NativeBatchNormBackward0]
	1948135819920 -> 1948135818576
	1948135819920 [label=ConvolutionBackward0]
	1948135104368 -> 1948135819920
	1948135104368 [label=CatBackward0]
	1948135101776 -> 1948135104368
	1948135101776 [label=ReluBackward0]
	1948135101440 -> 1948135101776
	1948135101440 [label=NativeBatchNormBackward0]
	1948135101584 -> 1948135101440
	1948135101584 [label=ConvolutionBackward0]
	1948135101008 -> 1948135101584
	1948135101008 [label=ReluBackward0]
	1948135101632 -> 1948135101008
	1948135101632 [label=NativeBatchNormBackward0]
	1948135102112 -> 1948135101632
	1948135102112 [label=ConvolutionBackward0]
	1948135102304 -> 1948135102112
	1948135102304 [label=MaxPool2DWithIndicesBackward0]
	1948135820160 -> 1948135102304
	1948135102208 -> 1948135102112
	1948912041872 [label="down_block_2.block.1.block.0.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	1948912041872 -> 1948135102208
	1948135102208 [label=AccumulateGrad]
	1948135101872 -> 1948135102112
	1948912041632 [label="down_block_2.block.1.block.0.bias
 (256)" fillcolor=lightblue]
	1948912041632 -> 1948135101872
	1948135101872 [label=AccumulateGrad]
	1948135102256 -> 1948135101632
	1948912038992 [label="down_block_2.block.1.block.1.weight
 (256)" fillcolor=lightblue]
	1948912038992 -> 1948135102256
	1948135102256 [label=AccumulateGrad]
	1948135101536 -> 1948135101632
	1948912039232 [label="down_block_2.block.1.block.1.bias
 (256)" fillcolor=lightblue]
	1948912039232 -> 1948135101536
	1948135101536 [label=AccumulateGrad]
	1948135102016 -> 1948135101584
	1948912039712 [label="down_block_2.block.1.block.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1948912039712 -> 1948135102016
	1948135102016 [label=AccumulateGrad]
	1948135101920 -> 1948135101584
	1948912039792 [label="down_block_2.block.1.block.3.bias
 (256)" fillcolor=lightblue]
	1948912039792 -> 1948135101920
	1948135101920 [label=AccumulateGrad]
	1948135101344 -> 1948135101440
	1948912039552 [label="down_block_2.block.1.block.4.weight
 (256)" fillcolor=lightblue]
	1948912039552 -> 1948135101344
	1948135101344 [label=AccumulateGrad]
	1948135104224 -> 1948135101440
	1948912040272 [label="down_block_2.block.1.block.4.bias
 (256)" fillcolor=lightblue]
	1948912040272 -> 1948135104224
	1948135104224 [label=AccumulateGrad]
	1948135101728 -> 1948135104368
	1948135101728 [label=ConvolutionBackward0]
	1948135102064 -> 1948135101728
	1948135102064 [label=ReluBackward0]
	1948135102736 -> 1948135102064
	1948135102736 [label=NativeBatchNormBackward0]
	1948135102592 -> 1948135102736
	1948135102592 [label=ConvolutionBackward0]
	1948135102688 -> 1948135102592
	1948135102688 [label=ReluBackward0]
	1948135102496 -> 1948135102688
	1948135102496 [label=NativeBatchNormBackward0]
	1948135102976 -> 1948135102496
	1948135102976 [label=ConvolutionBackward0]
	1948135103408 -> 1948135102976
	1948135103408 [label=CatBackward0]
	1948135103360 -> 1948135103408
	1948135103360 [label=ReluBackward0]
	1948135103456 -> 1948135103360
	1948135103456 [label=NativeBatchNormBackward0]
	1948135103168 -> 1948135103456
	1948135103168 [label=ConvolutionBackward0]
	1948135103936 -> 1948135103168
	1948135103936 [label=ReluBackward0]
	1948135103888 -> 1948135103936
	1948135103888 [label=NativeBatchNormBackward0]
	1948135104032 -> 1948135103888
	1948135104032 [label=ConvolutionBackward0]
	1948135103840 -> 1948135104032
	1948135103840 [label=MaxPool2DWithIndicesBackward0]
	1948135101776 -> 1948135103840
	1948135104320 -> 1948135104032
	1948912041072 [label="down_block_3.block.1.block.0.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	1948912041072 -> 1948135104320
	1948135104320 [label=AccumulateGrad]
	1948135104128 -> 1948135104032
	1948912040752 [label="down_block_3.block.1.block.0.bias
 (512)" fillcolor=lightblue]
	1948912040752 -> 1948135104128
	1948135104128 [label=AccumulateGrad]
	1948135103984 -> 1948135103888
	1948912041152 [label="down_block_3.block.1.block.1.weight
 (512)" fillcolor=lightblue]
	1948912041152 -> 1948135103984
	1948135103984 [label=AccumulateGrad]
	1948135104080 -> 1948135103888
	1948912041232 [label="down_block_3.block.1.block.1.bias
 (512)" fillcolor=lightblue]
	1948912041232 -> 1948135104080
	1948135104080 [label=AccumulateGrad]
	1948135103696 -> 1948135103168
	1948912039152 [label="down_block_3.block.1.block.3.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1948912039152 -> 1948135103696
	1948135103696 [label=AccumulateGrad]
	1948135103648 -> 1948135103168
	1948912041792 [label="down_block_3.block.1.block.3.bias
 (512)" fillcolor=lightblue]
	1948912041792 -> 1948135103648
	1948135103648 [label=AccumulateGrad]
	1948135103744 -> 1948135103456
	1948912038912 [label="down_block_3.block.1.block.4.weight
 (512)" fillcolor=lightblue]
	1948912038912 -> 1948135103744
	1948135103744 [label=AccumulateGrad]
	1948135101824 -> 1948135103456
	1948912038672 [label="down_block_3.block.1.block.4.bias
 (512)" fillcolor=lightblue]
	1948912038672 -> 1948135101824
	1948135101824 [label=AccumulateGrad]
	1948135103312 -> 1948135103408
	1948135103312 [label=ConvolutionBackward0]
	1948135103792 -> 1948135103312
	1948135103792 [label=ReluBackward0]
	1948135100816 -> 1948135103792
	1948135100816 [label=NativeBatchNormBackward0]
	1948135100720 -> 1948135100816
	1948135100720 [label=ConvolutionBackward0]
	1948135100768 -> 1948135100720
	1948135100768 [label=ReluBackward0]
	1948135100624 -> 1948135100768
	1948135100624 [label=NativeBatchNormBackward0]
	1948135100912 -> 1948135100624
	1948135100912 [label=ConvolutionBackward0]
	1948910361376 -> 1948135100912
	1948910361376 [label=MaxPool2DWithIndicesBackward0]
	1948135103360 -> 1948910361376
	1948910359168 -> 1948135100912
	1948912039632 [label="down_block_4.block.1.block.0.weight
 (1024, 512, 3, 3)" fillcolor=lightblue]
	1948912039632 -> 1948910359168
	1948910359168 [label=AccumulateGrad]
	1948910361904 -> 1948135100912
	1948912039872 [label="down_block_4.block.1.block.0.bias
 (1024)" fillcolor=lightblue]
	1948912039872 -> 1948910361904
	1948910361904 [label=AccumulateGrad]
	1948910359024 -> 1948135100624
	1948912038752 [label="down_block_4.block.1.block.1.weight
 (1024)" fillcolor=lightblue]
	1948912038752 -> 1948910359024
	1948910359024 [label=AccumulateGrad]
	1948910358832 -> 1948135100624
	1948912039312 [label="down_block_4.block.1.block.1.bias
 (1024)" fillcolor=lightblue]
	1948912039312 -> 1948910358832
	1948910358832 [label=AccumulateGrad]
	1948135100480 -> 1948135100720
	1948912038032 [label="down_block_4.block.1.block.3.weight
 (1024, 1024, 3, 3)" fillcolor=lightblue]
	1948912038032 -> 1948135100480
	1948135100480 [label=AccumulateGrad]
	1948135100864 -> 1948135100720
	1948912041392 [label="down_block_4.block.1.block.3.bias
 (1024)" fillcolor=lightblue]
	1948912041392 -> 1948135100864
	1948135100864 [label=AccumulateGrad]
	1948135100576 -> 1948135100816
	1948912038592 [label="down_block_4.block.1.block.4.weight
 (1024)" fillcolor=lightblue]
	1948912038592 -> 1948135100576
	1948135100576 [label=AccumulateGrad]
	1948135104272 -> 1948135100816
	1948912038512 [label="down_block_4.block.1.block.4.bias
 (1024)" fillcolor=lightblue]
	1948912038512 -> 1948135104272
	1948135104272 [label=AccumulateGrad]
	1948135103552 -> 1948135103312
	1948135469360 [label="up_block_1.up_conv.weight
 (1024, 512, 2, 2)" fillcolor=lightblue]
	1948135469360 -> 1948135103552
	1948135103552 [label=AccumulateGrad]
	1948135103600 -> 1948135103312
	1948135470880 [label="up_block_1.up_conv.bias
 (512)" fillcolor=lightblue]
	1948135470880 -> 1948135103600
	1948135103600 [label=AccumulateGrad]
	1948135103120 -> 1948135102976
	1948135472000 [label="up_block_1.double_conv.block.0.weight
 (512, 1024, 3, 3)" fillcolor=lightblue]
	1948135472000 -> 1948135103120
	1948135103120 [label=AccumulateGrad]
	1948135103264 -> 1948135102976
	1948135472560 [label="up_block_1.double_conv.block.0.bias
 (512)" fillcolor=lightblue]
	1948135472560 -> 1948135103264
	1948135103264 [label=AccumulateGrad]
	1948135102880 -> 1948135102496
	1948135472720 [label="up_block_1.double_conv.block.1.weight
 (512)" fillcolor=lightblue]
	1948135472720 -> 1948135102880
	1948135102880 [label=AccumulateGrad]
	1948135102784 -> 1948135102496
	1948135472960 [label="up_block_1.double_conv.block.1.bias
 (512)" fillcolor=lightblue]
	1948135472960 -> 1948135102784
	1948135102784 [label=AccumulateGrad]
	1948135102640 -> 1948135102592
	1948135472320 [label="up_block_1.double_conv.block.3.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1948135472320 -> 1948135102640
	1948135102640 [label=AccumulateGrad]
	1948135102544 -> 1948135102592
	1948135472240 [label="up_block_1.double_conv.block.3.bias
 (512)" fillcolor=lightblue]
	1948135472240 -> 1948135102544
	1948135102544 [label=AccumulateGrad]
	1948135102448 -> 1948135102736
	1948135471600 [label="up_block_1.double_conv.block.4.weight
 (512)" fillcolor=lightblue]
	1948135471600 -> 1948135102448
	1948135102448 [label=AccumulateGrad]
	1948135102400 -> 1948135102736
	1948135471840 [label="up_block_1.double_conv.block.4.bias
 (512)" fillcolor=lightblue]
	1948135471840 -> 1948135102400
	1948135102400 [label=AccumulateGrad]
	1948135101968 -> 1948135101728
	1948135471200 [label="up_block_2.up_conv.weight
 (512, 256, 2, 2)" fillcolor=lightblue]
	1948135471200 -> 1948135101968
	1948135101968 [label=AccumulateGrad]
	1948135100960 -> 1948135101728
	1948135471120 [label="up_block_2.up_conv.bias
 (256)" fillcolor=lightblue]
	1948135471120 -> 1948135100960
	1948135100960 [label=AccumulateGrad]
	1948135104176 -> 1948135819920
	1948135470560 [label="up_block_2.double_conv.block.0.weight
 (256, 512, 3, 3)" fillcolor=lightblue]
	1948135470560 -> 1948135104176
	1948135104176 [label=AccumulateGrad]
	1948135101248 -> 1948135819920
	1948135470720 [label="up_block_2.double_conv.block.0.bias
 (256)" fillcolor=lightblue]
	1948135470720 -> 1948135101248
	1948135101248 [label=AccumulateGrad]
	1948135101296 -> 1948135818576
	1948135470480 [label="up_block_2.double_conv.block.1.weight
 (256)" fillcolor=lightblue]
	1948135470480 -> 1948135101296
	1948135101296 [label=AccumulateGrad]
	1948135104464 -> 1948135818576
	1948135469280 [label="up_block_2.double_conv.block.1.bias
 (256)" fillcolor=lightblue]
	1948135469280 -> 1948135104464
	1948135104464 [label=AccumulateGrad]
	1948135818816 -> 1948135819056
	1948135469600 [label="up_block_2.double_conv.block.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1948135469600 -> 1948135818816
	1948135818816 [label=AccumulateGrad]
	1948135817472 -> 1948135819056
	1948135469520 [label="up_block_2.double_conv.block.3.bias
 (256)" fillcolor=lightblue]
	1948135469520 -> 1948135817472
	1948135817472 [label=AccumulateGrad]
	1948135817568 -> 1948135820208
	1948135469440 [label="up_block_2.double_conv.block.4.weight
 (256)" fillcolor=lightblue]
	1948135469440 -> 1948135817568
	1948135817568 [label=AccumulateGrad]
	1948135820256 -> 1948135820208
	1948135469120 [label="up_block_2.double_conv.block.4.bias
 (256)" fillcolor=lightblue]
	1948135469120 -> 1948135820256
	1948135820256 [label=AccumulateGrad]
	1948135819872 -> 1948135820544
	1948135470960 [label="up_block_3.up_conv.weight
 (256, 128, 2, 2)" fillcolor=lightblue]
	1948135470960 -> 1948135819872
	1948135819872 [label=AccumulateGrad]
	1948135820448 -> 1948135820544
	1948135470800 [label="up_block_3.up_conv.bias
 (128)" fillcolor=lightblue]
	1948135470800 -> 1948135820448
	1948135820448 [label=AccumulateGrad]
	1948135818768 -> 1948135818672
	1948135471360 [label="up_block_3.double_conv.block.0.weight
 (128, 256, 3, 3)" fillcolor=lightblue]
	1948135471360 -> 1948135818768
	1948135818768 [label=AccumulateGrad]
	1948135819344 -> 1948135818672
	1948135472080 [label="up_block_3.double_conv.block.0.bias
 (128)" fillcolor=lightblue]
	1948135472080 -> 1948135819344
	1948135819344 [label=AccumulateGrad]
	1948135818336 -> 1948135818096
	1948135471920 [label="up_block_3.double_conv.block.1.weight
 (128)" fillcolor=lightblue]
	1948135471920 -> 1948135818336
	1948135818336 [label=AccumulateGrad]
	1948135817856 -> 1948135818096
	1948135472640 [label="up_block_3.double_conv.block.1.bias
 (128)" fillcolor=lightblue]
	1948135472640 -> 1948135817856
	1948135817856 [label=AccumulateGrad]
	1948135148608 -> 1948135149040
	1948135507104 [label="up_block_3.double_conv.block.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1948135507104 -> 1948135148608
	1948135148608 [label=AccumulateGrad]
	1948135149184 -> 1948135149040
	1948135508384 [label="up_block_3.double_conv.block.3.bias
 (128)" fillcolor=lightblue]
	1948135508384 -> 1948135149184
	1948135149184 [label=AccumulateGrad]
	1948135148800 -> 1948135148752
	1948135509424 [label="up_block_3.double_conv.block.4.weight
 (128)" fillcolor=lightblue]
	1948135509424 -> 1948135148800
	1948135148800 [label=AccumulateGrad]
	1948135148560 -> 1948135148752
	1948135506704 [label="up_block_3.double_conv.block.4.bias
 (128)" fillcolor=lightblue]
	1948135506704 -> 1948135148560
	1948135148560 [label=AccumulateGrad]
	1948135148080 -> 1948135147744
	1948135509744 [label="up_block_4.up_conv.weight
 (128, 64, 2, 2)" fillcolor=lightblue]
	1948135509744 -> 1948135148080
	1948135148080 [label=AccumulateGrad]
	1948135147888 -> 1948135147744
	1948135509664 [label="up_block_4.up_conv.bias
 (64)" fillcolor=lightblue]
	1948135509664 -> 1948135147888
	1948135147888 [label=AccumulateGrad]
	1948135147552 -> 1948135147408
	1948135508544 [label="up_block_4.double_conv.block.0.weight
 (64, 128, 3, 3)" fillcolor=lightblue]
	1948135508544 -> 1948135147552
	1948135147552 [label=AccumulateGrad]
	1948135147696 -> 1948135147408
	1948135508944 [label="up_block_4.double_conv.block.0.bias
 (64)" fillcolor=lightblue]
	1948135508944 -> 1948135147696
	1948135147696 [label=AccumulateGrad]
	1948135147312 -> 1948135146928
	1948135509104 [label="up_block_4.double_conv.block.1.weight
 (64)" fillcolor=lightblue]
	1948135509104 -> 1948135147312
	1948135147312 [label=AccumulateGrad]
	1948135147216 -> 1948135146928
	1948135509184 [label="up_block_4.double_conv.block.1.bias
 (64)" fillcolor=lightblue]
	1948135509184 -> 1948135147216
	1948135147216 [label=AccumulateGrad]
	1948135147072 -> 1948135147168
	1948135509264 [label="up_block_4.double_conv.block.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1948135509264 -> 1948135147072
	1948135147072 [label=AccumulateGrad]
	1948135146976 -> 1948135147168
	1948135509504 [label="up_block_4.double_conv.block.3.bias
 (64)" fillcolor=lightblue]
	1948135509504 -> 1948135146976
	1948135146976 [label=AccumulateGrad]
	1948135146880 -> 1948135146112
	1948135509344 [label="up_block_4.double_conv.block.4.weight
 (64)" fillcolor=lightblue]
	1948135509344 -> 1948135146880
	1948135146880 [label=AccumulateGrad]
	1948135146832 -> 1948135146112
	1948135509904 [label="up_block_4.double_conv.block.4.bias
 (64)" fillcolor=lightblue]
	1948135509904 -> 1948135146832
	1948135146832 [label=AccumulateGrad]
	1948135146640 -> 1948135146496
	1948135506944 [label="conv.weight
 (6, 64, 1, 1)" fillcolor=lightblue]
	1948135506944 -> 1948135146640
	1948135146640 [label=AccumulateGrad]
	1948135146736 -> 1948135146496
	1948135506864 [label="conv.bias
 (6)" fillcolor=lightblue]
	1948135506864 -> 1948135146736
	1948135146736 [label=AccumulateGrad]
	1948135146496 -> 1948135506784
}
